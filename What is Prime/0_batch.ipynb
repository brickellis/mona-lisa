{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates the list of tasks to run.\n",
    "'''\n",
    "import json\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for num in range(1, 50001):\n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{num}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert mathematician.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "            Number: {str(num)}\n",
    "            ----\n",
    "            Please respond in JSON, with one key - `answer`. The value is whether or not the number above is prime. The possible values are either \"True\" or \"False\".\n",
    "            \"\"\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saves tasks to a file to upload.\n",
    "'''\n",
    "file_name = \"batchinput.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Uploads the input file.\n",
    "'''\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"batchinput.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input file object returned by OpenAI\n",
    "'''\n",
    "batch_input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates a batch job using the id in the input file object.\n",
    "'''\n",
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"Primes from 1 to 50,000\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Batch job object\n",
    "'''\n",
    "batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "List of batches (Useful if you have lost your batch job id. Can also be found using the website.)\n",
    "'''\n",
    "client.batches.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Returns the batch job object, updated with the current status of the job and other important details.\n",
    "Can often have an almost instantaneous turnaround. Depends on the batch size.\n",
    "'''\n",
    "batch_job_check = client.batches.retrieve(batch_job.id)\n",
    "\n",
    "print(batch_job_check)\n",
    "print()\n",
    "print(f'{batch_job_check.status=}')\n",
    "print(f'{batch_job_check.request_counts=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saves the output.\n",
    "'''\n",
    "file_response = client.files.content(batch_job_check.output_file_id)\n",
    "result_file_name = \"batchoutput.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(file_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
