{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import textwrap\n",
    "client = OpenAI()\n",
    "responses = []\n",
    "with open('batchoutput.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        responses.append(json.loads(line))\n",
    "\n",
    "print(len(responses))\n",
    "print(json.loads(responses[0]['response']['body']['choices'][0]['message']['content'])['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates the list of tasks to run.\n",
    "'''\n",
    "tasks = []\n",
    "\n",
    "for response in responses:\n",
    "    color = json.loads(response['response']['body']['choices'][0]['message']['content'])['description']\n",
    "    task = {\n",
    "        \"custom_id\": response['custom_id'],\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"temperature\": 0.1,\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a master of deciphering illustrative descriptions.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": textwrap.dedent(f\"\"\"\n",
    "            Description: {color}\n",
    "            ----\n",
    "            Please respond in JSON, with one key - `hexadecimal`. Return the hexadecimal value of the color described. Do not include anything else.\n",
    "            \"\"\"),\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saves it to a file which will be uploaded.\n",
    "'''\n",
    "file_name = \"batchinput2.jsonl\"\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Uploads the input file.\n",
    "'''\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"batchinput2.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input file object returned by OpenAI\n",
    "'''\n",
    "batch_input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates a batch job using the id in the input file object.\n",
    "'''\n",
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"The Mona Lisa Hexcodes\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Batch job object\n",
    "'''\n",
    "batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "List of batches (Useful if you have lost your batch job id. Can also be found using the website.)\n",
    "'''\n",
    "client.batches.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Returns the batch job object, updated with the current status of the job and other important details.\n",
    "Can often have an almost instantaneous turnaround. Depends on the batch size. The 50,000 took __ min.\n",
    "'''\n",
    "batch_job_check = client.batches.retrieve(batch_job.id)\n",
    "\n",
    "print(batch_job_check)\n",
    "print()\n",
    "print(f'{batch_job_check.status=}')\n",
    "print(f'{batch_job_check.request_counts=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saves the output.\n",
    "'''\n",
    "file_response = client.files.content(batch_job_check.output_file_id)\n",
    "result_file_name = \"batchoutput2.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(file_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
